{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96594b2f-f124-4525-9fa9-40bb109f9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import threading\n",
    "import motors\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from traitlets.config.configurable import HasTraits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5a1f494-8c0d-473e-938e-87510f4871b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-05 10:03:33 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-05 10:03:33 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-05 10:03:33 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-03-05 10:03:34 UTC][ZED][INFO] [Init]  Depth mode: ULTRA\n",
      "[2025-03-05 10:03:35 UTC][ZED][INFO] [Init]  Camera successfully opened.\n",
      "[2025-03-05 10:03:35 UTC][ZED][INFO] [Init]  Camera FW version: 1523\n",
      "[2025-03-05 10:03:35 UTC][ZED][INFO] [Init]  Video mode: HD1080@30\n",
      "[2025-03-05 10:03:35 UTC][ZED][INFO] [Init]  Serial Number: S/N 35129214\n",
      "242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-17 (_capture_frames), stopped 281471730118944)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1018, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1336, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\", line 707, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"_zmq.py\", line 1092, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1134, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1209, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 604, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\", line 707, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"_zmq.py\", line 1092, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1134, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1209, in zmq.backend.cython._zmq._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242"
     ]
    }
   ],
   "source": [
    "LIGHT_YELLOW = np.array([20,100, 100])\n",
    "DARK_YELLOW = np.array([30,255,255])\n",
    "\n",
    "\n",
    "class Camera(HasTraits):\n",
    "    color_value = traitlets.Any() # monitor the color_value variable\n",
    "    cx, cy = traitlets.Any(), traitlets.Any()\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.HD1080 #VGA(672*376), HD720(1280*720), HD1080 (1920*1080) or ...\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA  # Use ULTRA depth mode\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER  # Use meter units (for depth measurements)\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS: #Ensure the camera has opened succesfully\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "         # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width,self.height,sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width,self.height,sl.MAT_TYPE.F32_C4, sl.MEM.CPU) \n",
    "\n",
    "    def _capture_frames(self): #For data capturing only\n",
    "\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "           \n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "\n",
    "                frame = self.image.get_data()\n",
    "                frame[:720,:] = 0\n",
    "                scale = 0.2\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "\n",
    "                \n",
    "                hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "                mask = cv2.inRange(hsv, LIGHT_YELLOW, DARK_YELLOW)\n",
    "                kernel = np.ones((5,5), np.uint8)\n",
    "                mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                if contours:\n",
    "                    c = max(contours, key=cv2.contourArea)\n",
    "                    M = cv2.moments(c)\n",
    "                    if M[\"m00\"] > 0:\n",
    "                        self.cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                        self.cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "                        cv2.circle(frame, (self.cx, self.cy), 5, (0, 0, 255), -1)\n",
    "\n",
    "                        frame_center = frame.shape[1] // 2\n",
    "                        error = self.cx - frame_center\n",
    "                        correction = 0.1 * error\n",
    "                        #print(f\"error:  {error} correction: {correction}\")\n",
    "\n",
    "                #cv2.imshow(\"Original\", frame)\n",
    "                #cv2.imshow(\"Mask\", mask)\n",
    "                self.color_value = self.image.get_data()\n",
    "                #When displaying the images, the robot sends data to the computers. If the images are in very high resolution, it may cause network issues. Since the images are for display purposes only, please use a lower resolution if possible. Thank you.\n",
    "                scale = 0.1\n",
    "                resized_image = cv2.resize(self.color_value, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "                cv2.circle(resized_image, (int(self.width*scale//2),int(self.height*scale//2)), 1, (0, 255, 0))\n",
    "                display_color.value = bgr8_to_jpeg(frame)\n",
    "                \n",
    "                # self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                # depth_image_test = self.depth_image.copy()  #copy the depth image\n",
    "                # depth_image_test = np.nan_to_num(depth_image_test, nan=0.0).astype(np.float32)  # Change NaN value to 0\n",
    "                # depth_image_test[282:,:]=0\n",
    "                # depth_image_test[:,:168]=0\n",
    "                # depth_image_test[:,504:]=0\n",
    "\n",
    "                # depth_image_test[depth_image_test<100]=0\n",
    "                # depth_image_test[depth_image_test>1000]=0\n",
    "                # depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image_test, alpha=0.03), cv2.COLORMAP_JET)\n",
    "                #if(depth_image_test.max() == 0):\n",
    "                #    robot.left(1) #turn left at full speed\n",
    "                #    cv2.putText(depth_colormap, 'warning!!!', (336,188), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                #else:\n",
    "                #    distance = depth_image_test[depth_image_test!=0].min()\n",
    "                #    \n",
    "                #    if(distance < 400):\n",
    "                #        robot.left(1) #turn left at full speed\n",
    "                #        cv2.putText(depth_colormap, 'warning!!!', (336,188), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                #    else:\n",
    "                #        robot.forward(0.5) #move forward at half speed\n",
    "                    \n",
    "                # resized_depth_colormap=cv2.resize(depth_colormap, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "                display_depth.value = bgr8_to_jpeg(mask)\n",
    "                \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread\n",
    "            self.zed.close()\n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "camera = Camera()\n",
    "camera.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd113eb1-9ca2-452b-bde0-0b147b4b7219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9692afdeebe44bab1ef1cb876ba5985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='45%'), Image(value=b'', format='jpeg', width='45%')), laâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_color = widgets.Image(format='jpeg', width='45%') \n",
    "display_depth = widgets.Image(format='jpeg', width='45%')  \n",
    "layout=widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth],layout=layout) #horizontal \n",
    "display(sidebyside) #display the widget\n",
    "\n",
    "def func(change):\n",
    "    frame = change['new']\n",
    "    #display the first 100 images\n",
    "    scale = 0.1\n",
    "    resized_image = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    display_color.value = bgr8_to_jpeg(resized_image)\n",
    "    \n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(camera.depth_image , alpha=0.03), cv2.COLORMAP_JET)\n",
    "    resized_depth_colormap=cv2.resize(depth_colormap, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    display_depth.value = bgr8_to_jpeg(resized_depth_colormap)\n",
    "\n",
    "camera.observe(func, names=['color_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c592da-4b62-4294-aa3d-529750a1dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "\n",
    "def handleMotion(change):\n",
    "    temp = change['new']\n",
    "    OFFSET = 10\n",
    "    while True:\n",
    "        if temp > 540 + OFFSET:\n",
    "            robot.right(0.1)\n",
    "        elif temp < 540 - OFFSET:\n",
    "            robot.left(0.1)\n",
    "        else:\n",
    "            robot.forward(0.1)\n",
    "        print(temp, end='\\r')\n",
    "camera.observe(handleMotion, names=['cx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4bd3b7f-0ea1-42cb-a627-2913e2d8e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
